# Requirements for DeepSeek MoE Training
torch>=2.0.0
torchvision>=0.15.0
datasets>=2.12.0
transformers>=4.21.0
accelerate>=0.20.0
bitsandbytes>=0.39.0
wandb>=0.15.0
numpy>=1.21.0
scipy>=1.11.0
tqdm>=4.64.0
pyyaml>=6.0
tokenizers>=0.13.0

# Optional for GPU optimization
# flash-attn>=2.3.0
# triton>=2.0.0
# apex>=0.1

# Development tools
pytest>=7.0.0
black>=22.0.0
flake8>=5.0.0